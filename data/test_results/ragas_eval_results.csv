user_input,retrieved_contexts,response,reference,faithful_rate,llm_context_precision_without_reference,context_recall,context_entity_recall,answer_relevancy,faithfulness
What did Skyfire AI drone do during a traffic stop?,"['In January, a Skyfire AI drone was returning to base after responding to a false alarm when the police dispatcher asked us to reroute it to help locate a patrol officer. The officer had radioed a few minutes earlier that he had pulled over a suspicious vehicle and had not been heard from since. The officer had stopped where two major highways intersect in a complex cloverleaf, and dispatch was unsure exactly where they were located.']","The Skyfire AI drone was rerouted to help locate a police officer who had stopped a suspicious vehicle and hadn't been heard from since. The officer had stopped at a complex cloverleaf intersection of two major highways, and the drone's assistance was requested because dispatch was unsure of the officer's exact location. The drone was returning to base after a false alarm when it was redirected.",The Skyfire AI drone was redirected to find a missing officer during a traffic stop.,1.0,0.9999999999,1.0,0.3333333322222222,0.8169799689440914,1.0
When to use QLoRa?,[],I couldn't find specific articles for your query in my database üíÅ‚Äç‚ôÄÔ∏èPlease try rephrasing your question.,I couldn't find specific articles for your query in my database üíÅ‚Äç‚ôÄÔ∏èPlease try rephrasing your question.,0.0,0.0,0.0,0.0,0.0,0.0
Comparison between Gemma and different models,"['Gemma 3 4B achieves roughly comparable performance to Gemma 2 9B, Llama 3.1 8B, and Qwen2.5-7B. It‚Äôs slightly behind Microsoft Phi-4 Mini (also 4 billion parameters), except on MATH, according to that company‚Äôs tests.Gemma 3 12B improves on Gemma 2 27B and compares to Gemini 1.5 Flash (in TIGER-Lab‚Äôs tests) and Anthropic Claude 3.5 Haiku (in that developer‚Äôs tests). It outperforms the larger, proprietary models on MATH.']","Gemma 3 4B performs similarly to Gemma 2 9B, Llama 3.1 8B, and Qwen2.5-7B, but slightly trails Microsoft Phi-4 Mini (also a 4-billion parameter model) except in MATH performance, based on Microsoft's testing. Gemma 3 12B surpasses Gemma 2 27B and shows comparable performance to Gemini 1.5 Flash (according to TIGER-Lab's tests) and Anthropic Claude 3.5 Haiku (according to Anthropic's tests). It outperforms these larger, proprietary models on MATH. There is no relevant image available either.","Gemma 3 4B is comparable to Gemma 2 9B, Llama 3.1 8B, and Qwen2.5-7B, and slightly trails Microsoft Phi-4 Mini except on MATH.",1.0,0.9999999999,1.0,0.9999999983333333,0.7779951759228468,1.0
